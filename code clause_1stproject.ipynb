{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cfa9b1b",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc6e4412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38d1fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load the dataset into a Pandas DataFrame\n",
    "file_path = \"/Users/deeptilalwani/Documents/Data Science/code clause/task 1/creditcard.csv\"\n",
    "data = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19fa5623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Explore the dataset\n",
    "# 3.1: Display the first few rows of the dataset\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46fca10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Information about the dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 3.2: Get information about the dataset\n",
    "print(\"\\nInformation about the dataset:\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d58a6cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary statistics of the dataset:\n",
      "                Time            V1            V2            V3            V4  \\\n",
      "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
      "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
      "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
      "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
      "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
      "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
      "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
      "\n",
      "                 V5            V6            V7            V8            V9  \\\n",
      "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
      "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
      "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
      "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
      "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
      "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
      "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
      "\n",
      "       ...           V21           V22           V23           V24  \\\n",
      "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
      "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
      "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
      "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
      "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
      "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
      "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
      "\n",
      "                V25           V26           V27           V28         Amount  \\\n",
      "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
      "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
      "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
      "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
      "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
      "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
      "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
      "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
      "\n",
      "               Class  \n",
      "count  284807.000000  \n",
      "mean        0.001727  \n",
      "std         0.041527  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         0.000000  \n",
      "75%         0.000000  \n",
      "max         1.000000  \n",
      "\n",
      "[8 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# 3.3: Get summary statistics of the dataset\n",
    "print(\"\\nSummary statistics of the dataset:\")\n",
    "print(data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6708cb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of the target variable (Class):\n",
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3.4: Check the distribution of the target variable (Class)\n",
    "print(\"\\nDistribution of the target variable (Class):\")\n",
    "print(data['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700c0f59",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59223f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in the dataset:\n",
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values in the dataset:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e24e003",
   "metadata": {},
   "source": [
    "Since there are no missing values, we can skip the imputation step. We'll proceed with handling class imbalance using SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d30b3f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of the target variable (Class):\n",
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#  Handling Class Imbalance\n",
    "# Check the distribution of the target variable (Class)\n",
    "print(\"\\nDistribution of the target variable (Class):\")\n",
    "print(data['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd35e084",
   "metadata": {},
   "source": [
    "As we can see, there is a significant class imbalance in the dataset. The majority class (non-fraudulent transactions, labeled as 0) has 284,315 instances, while the minority class (fraudulent transactions, labeled as 1) has only 492 instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67fb1fd",
   "metadata": {},
   "source": [
    "we'll use the Synthetic Minority Over-sampling Technique (SMOTE) to oversample the minority class. This technique generates synthetic samples for the minority class to balance the class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb07fb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Handling Class Imbalance using SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de1fe8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target variable (y)\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7604e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d16c9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to create synthetic samples for the minority class\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "baaba40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of the target variable (Class) after SMOTE:\n",
      "0    284315\n",
      "1    284315\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of the target variable after SMOTE\n",
    "print(\"\\nDistribution of the target variable (Class) after SMOTE:\")\n",
    "print(y_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a256b46",
   "metadata": {},
   "source": [
    "Now that the class distribution is balanced, we can proceed with applying an anomaly detection algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f9e3c0",
   "metadata": {},
   "source": [
    "## Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c346978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomaly Detection using Isolation Forest\n",
    "from sklearn.ensemble import IsolationForest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e43165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Isolation Forest model\n",
    "isolation_forest = IsolationForest(contamination='auto', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b5ce6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the data and predict anomalies\n",
    "y_pred = isolation_forest.fit_predict(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "146d025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomalies are labeled as -1, and normal instances are labeled as 1\n",
    "# Convert the labels to match the original dataset (0 for normal, 1 for anomaly)\n",
    "y_pred[y_pred == 1] = 0  # Normal instances\n",
    "y_pred[y_pred == -1] = 1  # Anomalies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc15e22b",
   "metadata": {},
   "source": [
    "Anomalies are predicted using Isolation Forest, and their labels are converted to match the original dataset. Finally, the distribution of predicted anomalies is printed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e205c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of predicted anomalies:\n",
      "0    495783\n",
      "1     72847\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of predicted anomalies\n",
    "print(\"\\nDistribution of predicted anomalies:\")\n",
    "print(pd.Series(y_pred).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaae8aef",
   "metadata": {},
   "source": [
    "Anomalies are labeled as 1, and normal instances are labeled as 0.\n",
    "According to the distribution, there are 72,847 instances predicted as anomalies (labeled as 1) and 495,783 instances predicted as normal (labeled as 0).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a00886a",
   "metadata": {},
   "source": [
    "#### Let's experiment with different anomaly detection algorithms and hyperparameters to find the best-performing one. We'll use cross-validation to evaluate the models and select the one with the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2c74b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.covariance import EllipticEnvelope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2455ded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the dataset size by using a smaller subset (e.g., first 10000 samples)\n",
    "X_subset = X_resampled[:10000]\n",
    "y_subset = y_resampled[:10000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7dce26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary to store the models and their hyperparameters\n",
    "models = {\n",
    "    \"Isolation Forest\": IsolationForest(contamination='auto', random_state=42),\n",
    "    \"Local Outlier Factor\": LocalOutlierFactor(novelty=True),\n",
    "    \"One-Class SVM\": OneClassSVM(gamma='auto'),\n",
    "    \"Elliptic Envelope\": EllipticEnvelope(contamination=0.01 , support_fraction=0.7)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d0df58",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f7c0946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, average_precision_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d51ceebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Isolation Forest\n",
      "Precision: 0.0788, Recall: 1.0000, F1-score: 0.1462, AUC-PR: 0.0788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LocalOutlierFactor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LocalOutlierFactor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LocalOutlierFactor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LocalOutlierFactor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LocalOutlierFactor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Local Outlier Factor\n",
      "Precision: 0.0038, Recall: 1.0000, F1-score: 0.0076, AUC-PR: 0.0038\n",
      "Model: One-Class SVM\n",
      "Precision: 0.0038, Recall: 1.0000, F1-score: 0.0076, AUC-PR: 0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.578785769274148 > -118.408508434421947). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-124.658461522104488 > -126.408286789320044). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-120.308560132829996 > -121.676387675824259). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.396337078626118 > -120.242828360797517). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-120.516223200784154 > -120.907717196384269). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.638771295167572 > -120.524224136145122). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.972297145969435 > -122.441446952978026). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-124.658461522104488 > -125.761003615533923). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.999963720264390 > -118.549279449812403). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-150.710537291607721 > -154.986051776888445). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-152.179166881185978 > -154.415739994945852). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.973848691360516 > -120.955072492864446). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-126.051078294433353 > -127.429040077977561). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.484634426472184 > -118.697170899000440). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-152.268590266556515 > -152.775881240252630). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.210375501541989 > -120.336173252482837). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.370947554412780 > -116.642090106292045). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.248787042073175 > -119.335228501595978). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-159.076876707126047 > -159.998423915182258). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.933191337935568 > -121.266391665991094). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.865720070977034 > -118.566809981085868). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-85.892348597384483 > -86.505485420880291). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-85.536304874519359 > -85.888441188733225). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-152.467825498844263 > -152.868942585651354). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-85.656116874149589 > -85.976334291945776). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.327563816636697 > -118.917337002231108). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-84.297190824079834 > -86.597043000344300). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-88.477635856786918 > -88.634064269276521). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.956054576649535 > -120.230799677558878). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.796932065578758 > -117.605314354058990). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.748117567785826 > -118.829003204019500). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.575382544772168 > -118.186000065782594). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.099826122466027 > -119.792651549062157). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-84.503522371586271 > -85.392775153880407). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.746937379804038 > -117.669618018682144). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.961105385572125 > -120.962486898232953). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-93.655118482791877 > -94.993716146812815). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.414189375157022 > -119.627223064878237). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-150.851266502534941 > -155.095725227941131). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.485514470084013 > -118.440830697647868). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.621107410894808 > -117.970277721126564). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.365127546592817 > -119.887276094120182). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-87.308552661949804 > -87.581788691539046). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-84.694595546531417 > -88.281914340064674). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-86.465166604155414 > -87.415507749222840). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-85.894670816028196 > -87.250857518282587). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-88.833761978452060 > -90.092062138388783). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-88.033156454591847 > -88.948001316959960). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-95.453896998039653 > -96.032952397172608). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.114626601891885 > -119.753314013003120). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.822144298663190 > -118.249246603848690). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-120.009164571817379 > -120.284713712035085). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.783043481354198 > -123.778697328792731). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.022743673056553 > -117.673320594660723). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-87.980887349419220 > -90.702362005685742). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.530867070291606 > -119.269822345723426). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-83.120901651543193 > -85.879369775343420). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-84.174531451482864 > -85.241438235916220). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.963936539553401 > -119.909471219013540). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-87.479311573674593 > -88.023514040122848). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-121.007035787685936 > -125.750559017636192). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-90.196356920036550 > -90.623312586552558). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.801535695882279 > -120.882457037855346). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.664906393049407 > -120.132687938366402). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.333591070499523 > -120.328610688470690). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.239548453204222 > -120.062184480817393). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.640209914859327 > -122.760751322529259). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-150.564437489477172 > -153.220164459109839). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.528866707018238 > -119.158834803030430). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-88.719814980395199 > -93.870530103880569). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-84.420058833480738 > -84.491035091819327). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.341716164265890 > -119.909784383944398). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-117.316131753747044 > -118.195283097781413). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.444614067027061 > -118.923184426842667). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.419703550982177 > -121.231139936027716). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.674337198473268 > -120.813082191634592). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.526466176959516 > -120.329465876227061). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-115.522493178192335 > -116.756164155967937). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.366498313897679 > -120.004470668250264). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.440563771773952 > -120.609186638017007). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.539118309257177 > -122.399784801703646). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-83.426023528495847 > -83.570166214310177). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.166550955014316 > -120.995536529019247). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.645172987962681 > -119.079588469609874). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-85.787276748776577 > -86.412032334385614). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-150.728169263068082 > -153.830326783150838). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.403384604464719 > -119.463734721952932). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.727248612141238 > -119.020172596318190). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.930482326769919 > -118.930589212992928). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.721055931134501 > -120.058703453012754). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.189535921054798 > -119.285874433486683). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-149.163160413718344 > -149.208649580508080). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.230105515615691 > -120.935244130588245). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-121.309882174389301 > -123.470034508480467). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.592522470623379 > -117.688877401059884). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-87.733182712678484 > -89.905735814130338). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-120.543315663499783 > -122.114275225485841). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-118.911931377582761 > -120.139406445414309). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.739738305444263 > -122.505332105368709). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-152.865258240931354 > -154.203738927235378). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n",
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-116.692319468332315 > -118.056244795752917). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Elliptic Envelope\n",
      "Precision: 0.1154, Recall: 0.3158, F1-score: 0.1690, AUC-PR: 0.0390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deeptilalwani/Downloads/anaconda3/lib/python3.10/site-packages/sklearn/covariance/_robust_covariance.py:183: RuntimeWarning: Determinant has increased; this should not happen: log(det) > log(previous_det) (-119.455387305170717 > -122.657666482772086). You may want to try with a higher value of support_fraction (current value: 0.700).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Perform model evaluation for each model\n",
    "for name, model in models.items():\n",
    "    # Perform cross-validation using 5-fold cross-validation\n",
    "    y_pred = cross_val_predict(model, X_subset, y_subset, cv=5, n_jobs=-1)\n",
    "    \n",
    "    # Convert labels to match the original dataset (0 for normal, 1 for anomaly)\n",
    "    y_pred[y_pred == 1] = 0  # Normal instances\n",
    "    y_pred[y_pred == -1] = 1  # Anomalies\n",
    "    \n",
    "    try:\n",
    "        # Calculate evaluation metrics\n",
    "        precision = precision_score(y_subset, y_pred)\n",
    "        recall = recall_score(y_subset, y_pred)\n",
    "        f1 = f1_score(y_subset, y_pred)\n",
    "        auc_pr = average_precision_score(y_subset, y_pred)  \n",
    "    \n",
    "        # Print evaluation metrics\n",
    "        print(f\"Model: {name}\")\n",
    "        print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, AUC-PR: {auc_pr:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred for model {name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f142e1",
   "metadata": {},
   "source": [
    "The performance metric used is accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0779fe61",
   "metadata": {},
   "source": [
    "It seems like all models have very low precision, recall, F1-score, and AUC-PR values, indicating that they are not performing well for fraud detection on this dataset.\n",
    "\n",
    "Low recall indicates that the models are failing to identify a significant portion of the actual fraudulent transactions (i.e., many fraudulent transactions are being missed). Low precision suggests that a large number of the transactions flagged as fraudulent are actually legitimate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e46e51",
   "metadata": {},
   "source": [
    "### By fine-tuning the parameters of our chosen model, we can potentially achieve better performance without significantly altering the dataset or feature engineering.\n",
    "\n",
    "## hyperparameter tuning\n",
    "##### hyperparameter tuning process using grid search with a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f8d1a1",
   "metadata": {},
   "source": [
    "Based on the evaluation metrics, Isolation Forest seems to have the highest recall among the models, indicating that it's better at detecting anomalies. However, the precision is low, which means it might also misclassify some normal instances as anomalies. On the other hand, Elliptic Envelope has higher precision but lower recall compared to Isolation Forest.\n",
    "\n",
    "prioritizing detecting as many fraud cases as possible (even if it means some false positives), we might prefer Isolation Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cccee4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06114f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_samples': ['auto', 0.5, 0.7, 0.9],\n",
    "    'contamination': [0.01, 0.05, 0.1]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e967b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Isolation Forest model\n",
    "isolation_forest = IsolationForest(random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b90462a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the original dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8f49469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a subset of your original dataset\n",
    "X_subset, _, y_subset, _ = train_test_split(X_train, y_train, train_size=0.1, stratify=y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e40b6376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "501551d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=IsolationForest(random_state=42),\n",
       "             param_grid={'contamination': [0.01, 0.05, 0.1],\n",
       "                         'max_samples': ['auto', 0.5, 0.7, 0.9],\n",
       "                         'n_estimators': [50, 100, 200]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform grid search cross-validation on the subset\n",
    "grid_search = GridSearchCV(isolation_forest, param_grid, cv=5, scoring='roc_auc')\n",
    "grid_search.fit(X_subset, y_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "291d669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model\n",
    "best_isolation_forest = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2be844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the full dataset\n",
    "y_pred = best_isolation_forest.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "precision = precision_score(y_test, y_pred, average='micro')\n",
    "recall = recall_score(y_test, y_pred, average='micro')\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e759524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Isolation Forest Model Evaluation on Full Dataset:\n",
      "Precision: 0.0008, Recall: 0.0008, F1-score: 0.0008, ROC AUC: 0.2394\n"
     ]
    }
   ],
   "source": [
    "# Print or display the evaluation metrics\n",
    "print(\"Best Isolation Forest Model Evaluation on Full Dataset:\")\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, ROC AUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8d934f",
   "metadata": {},
   "source": [
    "The precision, recall, and F1-score are all around 0.0008, indicating poor performance. Additionally, the ROC AUC score is 0.2394, which also suggests that the model is not performing well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793988db",
   "metadata": {},
   "source": [
    "Feature Engineering: Explore additional feature engineering techniques to extract more relevant information from the data that could improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a9dfc9",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa52c67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e57c22a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for feature engineering\n",
    "def feature_engineering(data):\n",
    "    # Separate features and target variable\n",
    "    X = data.drop(columns=['Class'])\n",
    "    y = data['Class']\n",
    "    \n",
    "    # Normalize/Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Dimensionality reduction with PCA\n",
    "    pca = PCA(n_components=10)  # Adjust the number of components as needed\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    # Concatenate original features with PCA-transformed features\n",
    "    X_engineered = np.hstack((X_scaled, X_pca))\n",
    "    \n",
    "    return X_engineered, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54ec5b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature engineering to your dataset\n",
    "X_engineered, y = feature_engineering(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a1716f",
   "metadata": {},
   "source": [
    "Noe we train our anomaly detection mdoel on the engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83fcd57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the engineered features and target variable into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_engineered, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c06cbe77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(random_state=42)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train your anomaly detection model (e.g., Isolation Forest) on the training data\n",
    "# (Assuming you have already imported and initialized the Isolation Forest model)\n",
    "isolation_forest = IsolationForest(contamination='auto', random_state=42)\n",
    "isolation_forest.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87a51745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing data\n",
    "y_pred = isolation_forest.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "687190c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "roc_auc = roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d1c91e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Metrics:\n",
      "Precision: 0.0000\n",
      "Recall: 0.0002\n",
      "F1-score: 0.0000\n",
      "ROC AUC: 0.0914\n"
     ]
    }
   ],
   "source": [
    "# Print the evaluation metrics\n",
    "print(\"Model Evaluation Metrics:\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4b38cd",
   "metadata": {},
   "source": [
    "The evaluation metrics indicate very low performance for the model. The precision, recall, and F1-score are close to zero, and the ROC AUC is also very low. This suggests that the model is not effectively capturing the true positive instances of fraud.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2ae71f",
   "metadata": {},
   "source": [
    "using other basic classification algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7b32e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4e1661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the classifiers\n",
    "lr = LogisticRegression()\n",
    "svc = SVC()\n",
    "rf = RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1aa6a006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of classifiers\n",
    "models = {'Logistic Regression': lr, 'SVM': svc, 'Random Forest': rf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "42380561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f629a6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.9986, Precision: 0.6111, Recall: 0.5612, F1-score: 0.5851, ROC AUC: 0.7803\n",
      "Model: SVM\n",
      "Accuracy: 0.9983, Precision: 0.0000, Recall: 0.0000, F1-score: 0.0000, ROC AUC: 0.5000\n",
      "Model: Random Forest\n",
      "Accuracy: 0.9996, Precision: 0.9747, Recall: 0.7857, F1-score: 0.8701, ROC AUC: 0.8928\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    # Print the evaluation metrics\n",
    "    print(f'Model: {name}')\n",
    "    print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, ROC AUC: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2610c514",
   "metadata": {},
   "source": [
    "Logistic Regression achieved high accuracy (99.86%) and reasonably good precision (61.11%), recall (56.12%), F1-score (58.51%), and ROC AUC (78.03%).\n",
    "SVM achieved high accuracy (99.83%) but had very low precision, recall, and F1-score, indicating that it may not be suitable for this task.\n",
    "Random Forest achieved the highest accuracy (99.96%) among the three models and had excellent precision (97.40%), recall (76.53%), F1-score (85.71%), and ROC AUC (88.26%).\n",
    "\n",
    "Considering these results, Random Forest seems to be the best-performing model for this classification task, as it achieved the highest accuracy and good values for precision, recall, F1-score, and ROC AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3f277a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
